{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd\n",
    "import re as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get the company page that the user wants to scrape. We then check for an existing user credentials file or create one if its a first time user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Company Linkedin URL: https://www.linkedin.com/school/udacity/\n"
     ]
    }
   ],
   "source": [
    "#Get the Company's Linkedin URL from User\n",
    "page = input(\"Enter the Company Linkedin URL: \")\n",
    "company_name = page[33:-1]\n",
    "\n",
    "#See if existing user credential file exists or create one \n",
    "try:\n",
    "    f= open(\"linkedin_credentials.txt\",\"r\")\n",
    "    contents = f.read()\n",
    "    username = contents.replace(\"=\",\",\").split(\",\")[1]\n",
    "    password = contents.replace(\"=\",\",\").split(\",\")[3]\n",
    "except:\n",
    "    f= open(\"linkedin_credentials.txt\",\"w+\")\n",
    "    username = input('Enter your linkedin username: ')\n",
    "    password = input('Enter your linkedin password: ')\n",
    "    f.write(\"username={}, password={}\".format(username,password))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to get Selenium to use ChromeDriver to open chrome and visit Linkedin where it will sign in using your login info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing Chromedriver\n",
    "browser = webdriver.Chrome('chromedriver')\n",
    "\n",
    "\n",
    "#Open login page\n",
    "browser.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')\n",
    "\n",
    "#Enter login info:\n",
    "elementID = browser.find_element_by_id('username')\n",
    "elementID.send_keys(username)\n",
    "\n",
    "elementID = browser.find_element_by_id('password')\n",
    "elementID.send_keys(password)\n",
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrolling Down the Page\n",
    "We next search for the Linkedin page that we want to scrape. I’m into backpacking and the outdoors so I’ll use REI as an example. Now, this next section of code allows us to scroll down the entire Linkedin page. This is important because with an infinite scroll page such as Linkedin you would only get the first few posts without this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to company post webpage\n",
    "browser.get(page + 'posts/')\n",
    "\n",
    "\n",
    "#Simulate scrolling to capture all posts\n",
    "SCROLL_PAUSE_TIME = 1.5\n",
    "\n",
    "# Get scroll height\n",
    "last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Beautiful Soup…\n",
    "We will now collect the source code and then starting looking for the page elements that we want to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_page = browser.page_source\n",
    "\n",
    "#Check out page source code\n",
    "linkedin_soup = bs(company_page.encode(\"utf-8\"), \"html\")\n",
    "linkedin_soup.prettify()\n",
    "\n",
    "containers = linkedin_soup.findAll(\"div\",{\"class\":\"occludable-update ember-view\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the elements that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dates = []\n",
    "post_texts = []\n",
    "post_likes = []\n",
    "post_comments = []\n",
    "post_shared = []\n",
    "video_views = []\n",
    "media_links = []\n",
    "media_type = []\n",
    "\n",
    "for container in containers:\n",
    "\n",
    "    try:\n",
    "        posted_date = container.find(\"span\",{\"class\":\"visually-hidden\"})\n",
    "        text_box = container.find(\"div\",{\"class\":\"feed-shared-update-v2__description-wrapper\"})\n",
    "        text = text_box.find(\"span\",{\"dir\":\"ltr\"})\n",
    "        post_shares = container.findAll(\"li\", {'class':[\"social-details-social-counts__item--with-social-proof\",\"social-details-social-counts__comments social-details-social-counts__item\"]})\n",
    "        new_likes = container.findAll(\"li\", {'class':[\"social-details-social-counts__item--with-social-proof\",\"social-details-social-counts__item\"]})\n",
    "        new_comments = container.findAll(\"li\", {\"class\":[\"social-details-social-counts__item\" \"social-details-social-counts__comments social-details-social-counts__item--with-social-proof\"]})\n",
    "\n",
    "#         new_comments = container.findAll(\"button\", {\"class\": \"t-black--light t-12 hoverable-link-text\"})\n",
    "        \n",
    "        post_dates.append(posted_date.text.strip())\n",
    "        post_texts.append(text.text.strip())\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            video_box = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__content feed-shared-linkedin-video ember-view\"})\n",
    "            video_link = video_box[0].find(\"video\", {\"class\":\"vjs-tech\"})\n",
    "            media_links.append(video_link['src'])\n",
    "            media_type.append(\"Video\")\n",
    "        except:\n",
    "            try:\n",
    "                image_box = container.findAll(\"div\",{\"class\": \"feed-shared-image__container\"})\n",
    "                image_link = image_box[0].find(\"img\", {\"class\":\"ivm-view-attr__img--centered feed-shared-image__image feed-shared-image__image--constrained lazy-image ember-view\"})\n",
    "                media_links.append(image_link['src'])\n",
    "                media_type.append(\"Image\")\n",
    "            except:\n",
    "                try:\n",
    "                    #mutiple shared images\n",
    "                    image_box = container.findAll(\"div\",{\"class\": \"feed-shared-image__container\"})\n",
    "                    image_link = image_box[0].find(\"img\", {\"class\":\"ivm-view-attr__img--centered feed-shared-image__image lazy-image ember-view\"})\n",
    "                    media_links.append(image_link['src'])\n",
    "                    media_type.append(\"Multiple Images\")\n",
    "                except:\n",
    "                    try:\n",
    "                        article_box = container.findAll(\"div\",{\"class\": \"feed-shared-article__description-container\"})\n",
    "                        article_link = article_box[0].find('a', href=True)\n",
    "                        media_links.append(article_link['href'])\n",
    "                        media_type.append(\"Article\")\n",
    "                    except:\n",
    "                        try:\n",
    "                            video_box = container.findAll(\"div\",{\"class\": \"feed-shared-external-video__meta\"})          \n",
    "                            video_link = video_box[0].find('a', href=True)\n",
    "                            media_links.append(video_link['href'])\n",
    "                            media_type.append(\"Youtube Video\")   \n",
    "                        except:\n",
    "                            try:\n",
    "                                poll_box = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__content overflow-hidden feed-shared-poll ember-view\"})\n",
    "                                media_links.append(\"None\")\n",
    "                                media_type.append(\"Other: Poll, Shared Post, etc\")\n",
    "                            except:\n",
    "                                media_links.append(\"None\")\n",
    "                                media_type.append(\"Unknown\")\n",
    "\n",
    "\n",
    "\n",
    "        #Getting Video Views. (The folling three lines prevents class name overlap)\n",
    "#         view_container2 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__item\"]}))\n",
    "#         view_container1 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__reactions\",\"social-details-social-counts__comments social-details-social-counts__item\"]}))\n",
    "#         result = view_container2 - view_container1\n",
    "#         view_container = []\n",
    "#         for i in result:\n",
    "#             view_container += i\n",
    "\n",
    "#         try:\n",
    "#             video_views.append(view_container[1].text.strip().replace(' Views',''))\n",
    "\n",
    "#         except:\n",
    "#             video_views.append('N/A')\n",
    "\n",
    "\n",
    "        try:\n",
    "            post_likes.append(new_likes[0].text.strip())\n",
    "        except:\n",
    "            post_likes.append(0)\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            post_comments.append(new_comments[0].text.strip())                           \n",
    "        except:                                                           \n",
    "            post_comments.append(0)\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            post_shared.append(post_shares[1].text.strip())                           \n",
    "        except:                                                           \n",
    "            post_shared.append(0)\n",
    "            pass\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stripping non-numeric values\n",
    "comment_count = []\n",
    "for i in post_comments:\n",
    "    s = str(i).replace('comments','').replace('shares','').replace(' ','')\n",
    "    comment_count += [s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(post_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(post_shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing the Data for Export\n",
    "Finally, we are ready to organize our collected data into a Pandas DataFrame and then export it as a CSV or Excel file. You can find this file saved in the same folder that you ran the program from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Date_Posted\": post_dates,\n",
    "    \"Media_Type\": media_type,\n",
    "    \"Post_Caption\": post_texts,\n",
    "    \"Post_Likes_Counts\": post_likes,\n",
    "    \"Post_Comments_Counts\": post_comments,\n",
    "    \"Post_Shared_Counts\" : post_shared,\n",
    "#     \"Video Views\": video_views,\n",
    "#     \"Media Links\": media_links\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Exporting as csv file to program folder\n",
    "# df.to_csv(\"{}.csv\".format(company_name), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to Excel file to program folder\n",
    "writer = pd.Excelwriter = pd.ExcelWriter(\"{}.xlsx\".format(company_name), engine='xlsxwriter')\n",
    "df.to_excel(writer, index =False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
